{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import glob\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "\n",
    "class ShapeNetImageDataset(tfds.core.GeneratorBasedBuilder):\n",
    "    \"\"\"Short description of my dataset.\"\"\"\n",
    "\n",
    "    VERSION = tfds.core.Version('0.1.4')\n",
    "\n",
    "    def _info(self):\n",
    "        print(\"Shapenet!!!!\")\n",
    "        # Specifies the tfds.core.DatasetInfo object\n",
    "        return tfds.core.DatasetInfo(\n",
    "            builder=self,\n",
    "            # This is the description that will appear on the datasets page.\n",
    "            description=(\"This is the dataset for Shapenet Images. It contains yyy. The \"\n",
    "                         \"images are kept at their original dimensions.\"),\n",
    "            # tfds.features.FeatureConnectors\n",
    "            features=tfds.features.FeaturesDict({\n",
    "                \"image_description\": tfds.features.Text(),\n",
    "                \"image\": tfds.features.Image(shape = (128, 128, 1)),\n",
    "                # Here, labels can be of 5 distinct values.\n",
    "                \"label\": tfds.features.ClassLabel(num_classes=10),\n",
    "            }),\n",
    "            # If there's a common (input, target) tuple from the features,\n",
    "            # specify them here. They'll be used if as_supervised=True in\n",
    "            # builder.as_dataset.\n",
    "            supervised_keys=(\"image\", \"label\"),\n",
    "            # Homepage of the dataset for documentation\n",
    "            # Bibtex citation for the dataset\n",
    "            citation=r\"\"\"@article{shapenet-images-dataset-2020,\n",
    "                                  author = {Zen, Luo},\"}\"\"\",\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        # Downloads the data and defines the splits\n",
    "        # dl_manager is a tfds.download.DownloadManager that can be used to\n",
    "        # download and extract URLs\n",
    "\n",
    "        # Specify the splits\n",
    "        self.root = \"/hdd/zen/data/Reallite/Rendering/chair_cls1\"\n",
    "        classes = ['38436cce91dfe9a340b2974a4bd47901', 'ccfc857f35c138ede785b88cc9024b2a',\n",
    "                        '3fdc09d3065fa3c524e7e8a625efb2a7', '795f38ce5d8519938077cafed2bb8242',\n",
    "                        '30b0196b3b5431da2f95e2a1e9997b85', 'b405fa036403fbdb307776da88d1350f',\n",
    "                        '3af3096611c8eb363d658c402d71b967', 'ce8e6c13899376e2f3c9c1464e55d580',\n",
    "                        '4527cc19d2f09853a718067b9ac932e1', '124ef426dfa0aa38ff6069724068a578']\n",
    "        self.class_2_label = { classes[i]:i for i in range(len(classes))}\n",
    "\n",
    "        all_images = []\n",
    "        for class_name in classes:\n",
    "            all_image = sorted(glob.glob(os.path.join(self.root, \"data\", class_name, \"*-color.png\")))\n",
    "            all_image = [os.path.join(self.root, \"data\", class_name, i.split(\"/\")[-1].split(\"-\")[0])  for i in all_image]\n",
    "            all_images = all_images + all_image\n",
    "\n",
    "        self.data_list = all_images\n",
    "        np.random.shuffle(self.data_list)\n",
    "        split = 6/7\n",
    "\n",
    "        split_num = np.floor((1- split) * len(self.data_list)).astype(int)\n",
    "        self.test_data_list = self.data_list[:split_num]\n",
    "\n",
    "        split_num = np.floor((split) * len(self.data_list)).astype(int)\n",
    "        self.train_data_list = self.data_list[:split_num]\n",
    "\n",
    "        return [\n",
    "            tfds.core.SplitGenerator(\n",
    "                name=tfds.Split.TRAIN,\n",
    "                gen_kwargs={\n",
    "                    \"images_dir_path\": self.train_data_list,\n",
    "                },\n",
    "            ),\n",
    "            tfds.core.SplitGenerator(\n",
    "                name=tfds.Split.TEST,\n",
    "                gen_kwargs={\n",
    "                    \"images_dir_path\": self.test_data_list,\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, images_dir_path):\n",
    "        for image_dir in images_dir_path:\n",
    "#             img = Image.open('{}-color.png'.format(image_dir))\n",
    "            img = Image.open('{}-color.png'.format(image_dir))\n",
    "            img = np.array(img.convert('L'))[:,:,None]\n",
    "            meta = np.load('{}-meta.npz'.format(image_dir))\n",
    "            model_id = str(meta['model_id'])\n",
    "            label = self.class_2_label[model_id]\n",
    "            \n",
    "            yield image_dir, {\n",
    "                \"image_description\": image_dir,\n",
    "                \"image\": img,\n",
    "                \"label\": label,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 14:48:47.086307 139722210699008 dataset_builder.py:564] Found a different version 0.1.3 of dataset shape_net_image_dataset in data_dir /home/zen/tensorflow_datasets. Using currently defined version 0.1.4.\n",
      "I0501 14:48:47.094543 139722210699008 dataset_builder.py:187] Load pre-computed datasetinfo (eg: splits) from bucket.\n",
      "I0501 14:48:47.121437 139722210699008 dataset_builder.py:273] Generating dataset shape_net_image_dataset (/home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapenet!!!!\n",
      "\u001b[1mDownloading and preparing dataset shape_net_image_dataset (?? GiB) to /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 14:48:48.908228 139722210699008 dataset_builder.py:801] Generating split train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 15:02:00.235324 139722210699008 tfrecords_writer.py:78] Creating file /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-train.tfrecord-00000-of-00001\n",
      "I0501 15:02:00.808495 139722210699008 tfrecords_writer.py:175] Done writing /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-train.tfrecord. Shard lengths: [60000]\n",
      "I0501 15:02:00.809844 139722210699008 dataset_builder.py:801] Generating split test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 15:02:23.505398 139722210699008 tfrecords_writer.py:78] Creating file /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-test.tfrecord-00000-of-00001\n",
      "I0501 15:02:23.598534 139722210699008 tfrecords_writer.py:175] Done writing /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3/shape_net_image_dataset-test.tfrecord. Shard lengths: [10000]\n",
      "I0501 15:02:23.600071 139722210699008 dataset_builder.py:303] Computing statistics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b298b1fc62c64edc961cdc7179afb778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing statistics...', max=2.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 15:02:23.626622 139722210699008 dataset_builder.py:399] Constructing tf.data.Dataset for split test, from /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 15:02:34.811623 139722210699008 dataset_builder.py:399] Constructing tf.data.Dataset for split train, from /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4.incompleteW939Y3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDataset shape_net_image_dataset downloaded and prepared to /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sn_dataset_builder = ShapeNetImageDataset()\n",
    "sn_dataset_builder.download_and_prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 17:01:01.577212 139722210699008 dataset_builder.py:399] Constructing tf.data.Dataset for split train, from /home/zen/tensorflow_datasets/shape_net_image_dataset/0.1.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: {image: (128, 128, 1), image_description: (), label: ()}, types: {image: tf.uint8, image_description: tf.string, label: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "ds_train = sn_dataset_builder.as_dataset(split = \"train\")\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "datas = {i:[] for i in range(10)}\n",
    "images = []\n",
    "for example in ds_train.take(1000):  # Only take a single example\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "    curr_image = image.numpy()[:, :, 0].astype(np.float32)\n",
    "#     plt.imshow(curr_image, cmap=plt.get_cmap(\"gray\"))\n",
    "#     plt.show()\n",
    "    datas[label.numpy()].append(curr_image)\n",
    "#     print(\"Label: %d\" % label.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(10):\n",
    "    images = images + datas[i][:10]\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "im1 = np.arange(100).reshape((10, 10))\n",
    "im2 = im1.T\n",
    "im3 = np.flipud(im1)\n",
    "im4 = np.fliplr(im2)\n",
    "\n",
    "fig = plt.figure(dpi = 400)\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(3, 10),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, images):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im, cmap = \"gray\")\n",
    "\n",
    "plt.savefig(\"chairs.png\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reallite]",
   "language": "python",
   "name": "conda-env-reallite-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
